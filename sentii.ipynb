{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    data  \\\n",
      "0      রুদ্র জাহেদ ভাই খুব ভাল লাগল আপনার মন্তব্যে অন...   \n",
      "1      যারা ব্লগ দিয়ে ইন্টারনেট চালানোর দাবি করেছিল ২...   \n",
      "2                                      থ্যাংকস সুমন ভাই।   \n",
      "3                                      থ্যাংকস সুমন ভাই।   \n",
      "4                                  সময়ের নিষ্ঠ প্রতিবাদ।   \n",
      "5      সমস্যা বটে । আর একটা কারন হতে পারে \"নতুন ব্লগ ...   \n",
      "6      ভাল লিখেছেন। ধর্ষন খুব খারাপ কাজ।আমাদের সমাজে ...   \n",
      "7      আমিও চাই সব মানুষ মানুষ হিসেবে বাঁচুক । কিন্তু...   \n",
      "8      ভাল লিখেছেন। ধর্ষন খুব খারাপ কাজ।আমাদের সমাজে ...   \n",
      "9                                      থ্যাংকস সুমন ভাই।   \n",
      "10     সমস্যা বটে । আর একটা কারন হতে পারে \"নতুন ব্লগ ...   \n",
      "11     রুদ্র জাহেদ ভাই খুব ভাল লাগল আপনার মন্তব্যে অন...   \n",
      "12     আমিও চাই সব মানুষ মানুষ হিসেবে বাঁচুক । কিন্তু...   \n",
      "13     আমিও চাই সব মানুষ মানুষ হিসেবে বাঁচুক । কিন্তু...   \n",
      "14                                     থ্যাংকস সুমন ভাই।   \n",
      "15     আমিও চাই সব মানুষ মানুষ হিসেবে বাঁচুক । কিন্তু...   \n",
      "16                                 সময়ের নিষ্ঠ প্রতিবাদ।   \n",
      "17     রিকিপুভাই আপনে কি মুভি একা একা দেখেন এইটা কিন্...   \n",
      "18     তাই মনে হয়েছে বুঝি অনেক ধন্যবাদ ধ্রুবক আলো। ভা...   \n",
      "19     ভাল লিখেছেন। ধর্ষন খুব খারাপ কাজ।আমাদের সমাজে ...   \n",
      "20                                 সময়ের নিষ্ঠ প্রতিবাদ।   \n",
      "21     রুদ্র জাহেদ ভাই খুব ভাল লাগল আপনার মন্তব্যে অন...   \n",
      "22                                     থ্যাংকস সুমন ভাই।   \n",
      "23     সমস্যা বটে । আর একটা কারন হতে পারে \"নতুন ব্লগ ...   \n",
      "24                                     থ্যাংকস সুমন ভাই।   \n",
      "25     আমিও চাই সব মানুষ মানুষ হিসেবে বাঁচুক । কিন্তু...   \n",
      "26     রুদ্র জাহেদ ভাই খুব ভাল লাগল আপনার মন্তব্যে অন...   \n",
      "27                                           অন্যরকম ছিল   \n",
      "28     ট্রু চ্যাম্পিয়ন এন্ড লিজেন্ডারি ক্যারেকটার অফ ...   \n",
      "29                                                  বেশ।   \n",
      "...                                                  ...   \n",
      "27701  উপন্যাসে পরিণত করা যায় আমার অনেক গল্পই কিন্তু ...   \n",
      "27702  বিন্দু আর রেখার সাথে ইটিশ পিটিশন কিন্তু গোপন ব...   \n",
      "27703  শুঁটকি ভর্তা আমার দারুণ প্রিয় খাবার কিন্তু অাম...   \n",
      "27704  শুঁটকি ভর্তা আমার দারুণ প্রিয় খাবার কিন্তু অাম...   \n",
      "27705                                             স্যরি।   \n",
      "27706                                             স্যরি।   \n",
      "27707                            ধন্যবাদ ভাই কালের সময় ।   \n",
      "27708  কে কার কাছ থেকে কপি করেছে তা পরিষ্কার নয়। আপনি...   \n",
      "27709  সবসময় স্বাগত জানাই। আপনার পরিদর্শন এবং মন্তব্...   \n",
      "27710  তবুও কেন ফিরে আসে তার ছায়া-মায়া এ পার্থিব জগতে...   \n",
      "27711   বয়স কত কন্যার কন্যার জন্য ভালবাসা রইল । ধন্যবাদ   \n",
      "27712   বয়স কত কন্যার কন্যার জন্য ভালবাসা রইল । ধন্যবাদ   \n",
      "27713  রমজান মাসে এমন গুরুত্বপূর্ণ লেখার জন্য লেখক কে...   \n",
      "27714  গোধূলী রঙ এর সাথে একমত এই রোগের কোন প্রতিষেধক ...   \n",
      "27715  আচ্ছা আচ্ছা। বুঝেছি। মানে শব্দটা হতেছিল শব্দটা...   \n",
      "27716  আচ্ছা আচ্ছা। বুঝেছি। মানে শব্দটা হতেছিল শব্দটা...   \n",
      "27717    আরে ভাই এদের জ্বালায় ভাল মানুষ হইয়া চলা মুসকিল।   \n",
      "27718  ভাল বিষয়ের উপর লিখেছেন আমরা আমাদের নাটকের মান ...   \n",
      "27719  ভাল বিষয়ের উপর লিখেছেন আমরা আমাদের নাটকের মান ...   \n",
      "27720  কুসংস্কারাচ্ছন্ন মানুষের কাছে এর চেয়ে ভালো কী ...   \n",
      "27721  কুসংস্কারাচ্ছন্ন মানুষের কাছে এর চেয়ে ভালো কী ...   \n",
      "27722  পোস্ট একবার পড়েছি মন্তব্য গুলি বেশ কয়েকবার পড়ে...   \n",
      "27723               ধন্যবাদ সিরিজ জুড়ে সাথে থাকার জন্যে।   \n",
      "27724                            ১ এবং ২ বেশি ভালো লাগল।   \n",
      "27725                            ১ এবং ২ বেশি ভালো লাগল।   \n",
      "27726                         জেনে খুশি হলাম। শুভ কামনা।   \n",
      "27727             সুমন কর ধন্যবাদ আপনাকে ব্লগে আসার জন্য   \n",
      "27728  জারজ হলেও কৃষ্ণের গায়ে যে রাজ রক্ত ছিল এটা দুঃ...   \n",
      "27729  প্রামানিক জীবননাট্যের অন্ধকার আলোহীন একটা অধ্য...   \n",
      "27730  প্রামানিক জীবননাট্যের অন্ধকার আলোহীন একটা অধ্য...   \n",
      "\n",
      "                              title  \n",
      "0                     Love(ভালবাসা)  \n",
      "1                        Like (ভাল)  \n",
      "2                        Like (ভাল)  \n",
      "3                        Like (ভাল)  \n",
      "4          Consciousness (চেতনাবাদ)  \n",
      "5                        Like (ভাল)  \n",
      "6         Protestant (প্রতিবাদমূলক)  \n",
      "7                  Smiley (স্মাইলি)  \n",
      "8                        Like (ভাল)  \n",
      "9                        Like (ভাল)  \n",
      "10                 Smiley (স্মাইলি)  \n",
      "11                Angry (রাগান্বিত)  \n",
      "12         Consciousness (চেতনাবাদ)  \n",
      "13               Blush(গোলাপী আভা)  \n",
      "14                 Smiley (স্মাইলি)  \n",
      "15               Blush(গোলাপী আভা)  \n",
      "16                    Love(ভালবাসা)  \n",
      "17          Skip ( বোঝতে পারছি না )  \n",
      "18      Rocking (আন্দোলিত হত্তয়া)  \n",
      "19                    Fail (ব্যর্থ)  \n",
      "20                 Smiley (স্মাইলি)  \n",
      "21         Consciousness (চেতনাবাদ)  \n",
      "22                Angry (রাগান্বিত)  \n",
      "23                    Love(ভালবাসা)  \n",
      "24         Consciousness (চেতনাবাদ)  \n",
      "25     Shocking (অতিশয় বেদনাদায়ক)  \n",
      "26                    WOW(কি দারুন)  \n",
      "27                       Like (ভাল)  \n",
      "28                 Smiley (স্মাইলি)  \n",
      "29                       Like (ভাল)  \n",
      "...                             ...  \n",
      "27701                    Like (ভাল)  \n",
      "27702                    Like (ভাল)  \n",
      "27703                   HaHa(হা হা)  \n",
      "27704                    Like (ভাল)  \n",
      "27705                 Sad (দু: খিত)  \n",
      "27706                 Sad (দু: খিত)  \n",
      "27707       Skip ( বোঝতে পারছি না )  \n",
      "27708       Skip ( বোঝতে পারছি না )  \n",
      "27709                    Like (ভাল)  \n",
      "27710                 Love(ভালবাসা)  \n",
      "27711                    Like (ভাল)  \n",
      "27712                    Like (ভাল)  \n",
      "27713                    Like (ভাল)  \n",
      "27714       Skip ( বোঝতে পারছি না )  \n",
      "27715                    Like (ভাল)  \n",
      "27716                    Like (ভাল)  \n",
      "27717                  Evil (জঘন্য)  \n",
      "27718              Smiley (স্মাইলি)  \n",
      "27719              Smiley (স্মাইলি)  \n",
      "27720                  Evil (জঘন্য)  \n",
      "27721                  Evil (জঘন্য)  \n",
      "27722                    Like (ভাল)  \n",
      "27723                    Like (ভাল)  \n",
      "27724                    Like (ভাল)  \n",
      "27725                    Like (ভাল)  \n",
      "27726                    Like (ভাল)  \n",
      "27727                    Like (ভাল)  \n",
      "27728                    Like (ভাল)  \n",
      "27729                    Like (ভাল)  \n",
      "27730                    Like (ভাল)  \n",
      "\n",
      "[27731 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "df = pd.read_csv('sentiment.csv')\n",
    "\n",
    "col = ['data', 'title']\n",
    "df = df[col]\n",
    "df = df[pd.notnull(df['data'])]\n",
    "df.columns = ['data', 'title']\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['category_id'] = df['title'].factorize()[0]\n",
    "category_id_df = df[['title', 'category_id']].drop_duplicates().sort_values('category_id')\n",
    "category_to_id = dict(category_id_df.values)\n",
    "id_to_category = dict(category_id_df[['category_id', 'title']].values)\n",
    "# print(df.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27731, 20759)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##data absorbing done\n",
    "\n",
    "##feature extraction begins here\n",
    "\n",
    "\n",
    "##tf-idf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2), stop_words='english')\n",
    "features = tfidf.fit_transform(df.data).toarray()\n",
    "labels = df.category_id\n",
    "print(features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##uni and bi-grams\n",
    "\n",
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np\n",
    "N = 2\n",
    "for Product, category_id in sorted(category_to_id.items()):\n",
    "  features_chi2 = chi2(features, labels == category_id)\n",
    "  indices = np.argsort(features_chi2[0])\n",
    "  feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "  unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "  bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "  # print(\"# '{}':\".format(Product))\n",
    "  # print(\"  . Most correlated unigrams:\\n. {}\".format('\\n. '.join(unigrams[-N:])))\n",
    "  # print(\"  . Most correlated bigrams:\\n. {}\".format('\\n. '.join(bigrams[-N:])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##first test model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['data'], df['title'], random_state = 0)\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##first test models ends here\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "models = [\n",
    "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
    "    LinearSVC(),\n",
    "    MultinomialNB(),\n",
    "    LogisticRegression(random_state=0),\n",
    "]\n",
    "CV = 5\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "for model in models:\n",
    "  model_name = model.__class__.__name__\n",
    "  accuracies = cross_val_score(model, features, labels, scoring='accuracy', cv=CV)\n",
    "  for fold_idx, accuracy in enumerate(accuracies):\n",
    "    entries.append((model_name, fold_idx, accuracy))\n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name\n",
      "LinearSVC                 0.239011\n",
      "LogisticRegression        0.393388\n",
      "MultinomialNB             0.393317\n",
      "RandomForestClassifier    0.400058\n",
      "Name: accuracy, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(cv_df.groupby('model_name').accuracy.mean())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
